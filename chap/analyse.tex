The energy deposit measured per event by CASTOR can be shown as a 2D histogram with 16x14 pixels. The information of the amount of energy deposit is transmitted through the intensity of the colour. With a convolutional neural network it should be possible to learn the distinctive patterns of different types of particles and therefore to classify events correctly. 

\section{Data}
To train the network a sufficiently high amount of simulations are needed. For training and validation Monte Carlo events generated by the PYTHIA8 and the EPOS generator are used. To separate actual events from background noise a typical minimum bias event selection was made. Only events which trigger an energetic response higher than 5 GeV in the CaloTowers with a pseudorapidity range of 3.1 < $|\eta|$ < 5 are used in the analysis. To simplify the work for the neural network, only events containing isolated particles in CASTOR are used for differentiation. Here an isolated particle is defined by a minimum distance of $\Delta$R = $\sqrt{(\Delta \phi)^2 + (\Delta \eta)^2}$ = 0.8 to the next particles generated by the same event. Therefore every generated event is checked for isolated particles travelling through CASTOR.

Within CASTOR different types of particles leave different characteristic signatures which can be used to identify the particles. In fig. \ref{signals} the different types of signals can be seen. Electromagnetic light particles, such as electrons, positrons and photons, have a very large cross section and interact with the electromagnetic part of the calorimeter. In the energy deposit histogram very high energies are measured within the first two sections while nearly no energy is deposited in the hadronic rear sections.
When hadrons reach the calorimeter they interact and produce several lighter secondary particles which in turn interact again. The energy deposit is therefore distributed wider and reaches its peak within the hadronic sections of the calorimeter.
Muons very sparsely interact with the material of the calorimeter and pass it nearly without losing energy. A muon track is normally contained within one tower but can be seen as a very small energy deposit in every section.

Every histogram containing the energy deposit has a corresponding label vector. This is a binary vector, where the first index corresponds to isolated electron, positron or photon, the second to isolated hadron and the third to background. Here background is everything besides an isolated electron/photon or hadron. Therefore the categories do not exclude each other, since it is possible that an isolated electron and an isolated hadron travel through CASTOR in the same event. In table \ref{particlecounts} the particles and their frequency are listed. For this 500.000 Monte Carlo events are evaluated and only those particles with the beforementioned minimum distance are counted. For a neural network typically at least 1000 samples per class are needed to pick up the identifying features. As can be seen most particles are too few for a full training, whereas the differentiation between electrons/photons (which produce nearly the same signal) and hadrons seems possible. Even though muons have an especially distinctive signal, their number is too small to include them as a separate category.

\begin{figure}
\centering
\begin{minipage}[t]{0.95\textwidth}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=\textwidth]{electronhist.pdf}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=\textwidth]{muonhist.pdf}
\end{minipage}
\end{minipage}
\begin{minipage}[b]{0.95\textwidth}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=\textwidth]{pionhist.pdf}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=\textwidth]{protonhist.pdf}
\end{minipage}
\end{minipage}
\caption{Energy deposit of single particles travelling through CASTOR. An electron or photon (upper left) deposits its whole energy in the electromagnetic sections, while a muon travels with only a little energy loss through every section (upper right). The signals of pions and protons is spread wider and reaches into the hadronic sections of the calorimeter (lower left and right). The data is generated by EPOS.}
\label{signals}
\end{figure}

As seen in fig. \ref{signals}, the energy deposited in CASTOR by different particles varies much. In different events particles with very different energies are created. For example the kinetic energy of a proton can be between one and several thousand GeV. To learn that these very different signals are generated by the same particle type would pose a challenge for the neural network. Every histogram is therefore normalized to 1 in signal amplitude. 
\begin{table}
\centering
\caption{Number of isolated particles travelling through CASTOR in 500.000 Monte Carlo-generated events of proton-proton collisions at $\sqrt{\mathrm{s}} = 13\,$TeV. If not specified otherwise, the numbers include the particle and the antiparticle. As can be seen, hadrons and electrons/photons dominate the spectrum.}
\sffamily
\begin{tabular}{cc |cc }
\hline
Leptons/Bosons & Count & Hadrons & Count \\ \hline
Photon & 170047 & $\pi^+$ & 106904 \\
Positron & 243 & $\pi^-$ & 103648 \\
Electron & 250 & $K^+ / K^-$ & 27591 \\
Muon & 29 & Proton & 15782\\
$\nu_{\mu}$ & 27 & Neutron & 15232 \\
$\nu_e$ & 11 & $K^0_L$ & 13604 \\
$\nu_{\tau}$ & 1 &  $\Lambda$ & 5308\\
& & $\Sigma^+$ & 2016 \\
& & $\Sigma$ & 1993 \\
& & $\Sigma^-$ & 1993 \\
& & $K^0_s$ & 1323 \\
& & $\Xi^0$ & 511 \\
& & $\Xi^-$ & 471 \\
& & $\Omega^-$ & 16 \\
 \hline
\end{tabular}
\label{particlecounts}
\end{table}
\section{Network design}
The energy deposit histograms of CASTOR can be treated as pictures with 16 to 14 pixels and varying amounts of colour intensity. In order to remove the enourmous energy dependence of the calorimeter response, all events are scaled to the same signal amplitude. To design a neural network which can classify events into particle categories techniques in image recognition should be used. In normal classification problems convolutional layers with a small and quadratic kernel size are used. Here the information given by the underlying physics can be used to the advantage of the network. 

As particles reach the calorimeter from the left, it is not useful to use small kernel sizes to cover the whole image. Small, light particles are normally contained in one tower or at most two. Therefore convolutional layers with kernel sizes of one or two towers, meaning one or two pixels in the height and 7 or 14 in the width, should be able to recognize the important features of the tracks. Several layers, each with kernel sizes with a width of 14 pixels but varying heights are concatenated in the beginning of the network. In the deeper layers of the network, smaller kernel sizes can be used, since the convolution shrinks the signal size travelling through the neurons. A vast number of different network topologies had been tested during this thesis. In fig. \ref{convnet} the best-working network structure is shown. At first a kernel size of 1x7 is chosen. This kernel contains one tower so the significant features of lighter particles can be detected in this first layer. As a bit of an overlap is chosen to be able to find particles who penetrate deeper into CASTOR the resulting signal size in width is 4.. The height is not reduced as the kernel only contains one pixel in height at a time. In depth a rather large filter size is being used to recognize varying features of incoming particles. Therefore the depth dimension after the first convolutional layer is 384. After that the signal does not directly correspond to the pyhsical information anymore. That is why quadratic kernel sizes and a large overlap is used. These two features of the kernel enables the network to pick up on signatures corresponding to heavier particles. At first a kernel size of 5x5  is used, with 128 different filters. Afterwards a smaller kernel with only 3x3 in width and height is applied. The step size is both times chosen as one to have a maximum overlap. This reduces a possible loss of information. At the end the data is flattened. This happens before the first dense layer as the data structure is of no importance for a dense layer. At the end he data has to be converted into a one dimensional feature vector in every case to be used for the final classification. The last dense layer converts the data into a single classification vector with as many entries as existing classes. Because of the large kernel sizes in the beginning, the size of the data volume shrinks quickly. Max pooling was therefore omitted as too much information was lost due to the rather small input size. Deeper networks with more hidden layers have been tested but showed no advantage in accuracy. Deeper networks only need more computing time and have a higher tendency to overfit as more free parameters are available. 

\begin{figure}
\includegraphics[scale=0.75]{convnet_fig2.png}
\caption{The network design for the convolutional neural network. The first convolutional layer is composed out of kernel sizes of (1, 7), (2, 7) and (3, 7). This was omitted for a clearer picture. To reduce overfitting, dropout is used between after the first convolutional layer and before and after the first dense layer, each with a probability of 0.5. \protect \footnotemark}
\label{convnet}
\end{figure}

\section{Monitoring}
For monitoring the progress of a neural network, the first important feature is the loss function. As the classification problem is a multi-label classification, the loss function used here is the binary crossentropy loss. Every epoch it is calculated for the training and for the validation data set. Both variables need to decrease during the training. To determine if the input is correctly put into the network the first step was to train without any dropout or pooling layers. The network should overfit on the training set if given enough time. In fig. \ref{overfitacc} the loss and the accuracy of the training while overfitting can be seen.
\footnotetext{This figure is generated by adapting the code from \url{https://github.com/gwding/draw_convnet}}
\begin{figure}
\centering
\includegraphics[scale=0.8]{trainvalacc.png}
\caption{Training and validation accuracy. Both start at roughly the same percentage, but as training goes on, the training accuracy increases constantly. The validation accuracy does not change or even decreases a little. This is a classic overfitting effect.}
\label{overfitacc}
\end{figure}
As standard networks normally deal with multi-class and not multi-label problems, it proved to be useful to additionally monitor variables commonly used in classification problems. Here recall and precision were implemented \cite{rijsbergen}. With recall, the false negatives are taken into account, while precision monitors the false positives. Recall is also called the sensitivity of a network and is calculated by
\begin{equation}
\mathrm{Recall} = \frac{tp}{tp + fn} \quad ,
\label{recall}
\end{equation}
where $tp$ stands for true positive, $tn$ for false negative. The recall therefore is the fraction of true positive labels over all actually positive labels. In the case of all labels being correctly predicted, the recall is 1. Precision is also referred to as the positive predictive value. It is the rate of all correctly classified positive labels over all positively predicted labels.
\begin{equation}
\mathrm{Precision} = \frac{tp}{tp + fp}
\end{equation}
The nomenclature is the same, $tp$ for true positives and $fp$ for false positives. When all labels are correctly predicted, the precision also equals 1.

The precision and the recall can be calculated separately for the different categories. It can be easily monitored if the networks has more problems recognizing one category over the others. 
 
\section{Evaluation}
In the process of training it became apparent that no real physical features were being learned by the network. The training loss decreased but the validation remained constant over several hundred epochs (fig. \ref{trainvalloss}). To see if a network is per se working, a test without regulations, that means, without methods as dropout and pooling, can be performed. If the network then reaches a very high accuracy in classifying the training data, then it is working correctly in terms of converting and processing the input data. If the performance with regulations on a validation data set is still bad, the error does not lie within the network's data processing. As mentioned previously this has been tested and the network classified the training data up to nearly 100 \% accuracy. This lead to reevaluating the input data, as it seemed to be difficult for the network to generalize the underlying physical laws. 

\begin{figure}
\centering
\begin{minipage}{0.45\textwidth}
\centering
\includegraphics[scale=0.45]{trainloss.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\centering
\includegraphics[scale=0.45]{valloss.png}
\end{minipage}
\caption{Training and validation loss for single particles. The training loss behaves exactly as it is supposed to, decreasing gradually during training. The validation loss shows that the network is not generalizing properly. It is remaining constant or even increasing, showing that the error rates get higher.}
\label{trainvalloss}
\end{figure}

One problem that I identified is the definition of background events. When only strictly isolated particles are considered, there are many  background events that also contain very prominent hadrons or electrons and photons, but just not in the right distance to other particles travelling through CASTOR. The background category therefore contains a significant fracture of events which can not be distinguished from an photon or hadron event. To investigate this problem, two different approaches are chosen. The first one was to completely ignore the background category and turn the classification into a binary problem, only distinguishing between electromagnetic particles, photons as well as electrons, and hadrons. The second was the redefinition of the background category, where only true background events are used. True background meant, that no particle with an energy higher than 3 GeV had travelled through CASTOR in the corresponding event. As a further test the classification of only single particles is evaluated, meaning that only one particle per event crossed CASTOR. In tab. \ref{singleparticles} the particles belonging to this data set are listed. The background category consists mostly of no particles, which is not shown here. As single particles are more rare than isolated particles, two million events were evaluated. Still the number of events containing single particles is smaller than the number of events with isolated particles, where 500.000 events were evaluated.

\begin{table}
\centering
\caption{Single particles crossing through CASTOR. The particles in the background category are no single particles but have an energy less than 3 GeV. Two million events were evaluated.}
\sffamily
\begin{tabular}{cccc}\hline
Particle & Electromagnetic Class & Hadronic Class & Background Class \\ \hline
$\Lambda$ & 0 & 641 & 0 \\
Proton & 0 & 1915 & 0 \\
Neutron & 0 & 2355 & 0 \\
Electron  & 64 & 0 & 11 \\
Photon & 18327 & 0 & 80 \\
Pi$^{+-}$ & 0 & 25292 & 3 \\ 
K$^{+-}$ & 0 & 3608 & 0 \\
K$_l$ & 0 & 1769 & 0 \\
K$_s$ & 0 & 1812 & 0 \\
$\Omega^-$ & 0 & 3 & 0 \\
$\Xi^0$ & 0 & 53 & 0 \\
$\Xi^-$ & 0 & 52 & 0 \\
$\Sigma^+$ & 0 & 263 & 0 \\
$\Sigma^-$ & 0 & 384 & 0 \\
\hline
\end{tabular}
\label{singleparticles}
\end{table}


Furthermore, precision and recall are implemented as to monitor the network's performance, so their value is calculated after every epoch. In the first few training sessions the monitoring of these showed that while the mean loss decreases and the accuracy increased, the recall especially of electrons remained really low. To counteract this, the binary crossentropy loss is defined as a separate function. The crossentropy is the sum of two parts, one evaluating and penalizing the number of false positives, the other watching the number of false negatives. To counteract this, as recall returns the number of false negatives as seen in eq. (\enquote{\ref{recall}}), the crossentropy is adjusted to stronger penalize the false negatives in comparison to the false positives.

\subsection{Comparison between different data inputs}

To evaluate the possible applications and limits of the event classification with the help of a neural network, several data sets have been used and compared. As the first idea was to classify isolated particles, one dataset is composed of isolated electromagnetic particles, isolated hadronic particles and background, in which no isolated particle crosses CASTOR. All particles included in this data can be seen in table \ref{particlecounts}. As the background definition for this data type was difficult and the distinguishing between events with more than one particle to those with only one also seemed to worsen the performance of the network, single particle classes are introduced. Only events in which just one particle crosses through CASTOR are counted here. To also better define the background class, events with particle energies not higher than 3 GeV, or no particle in CASTOR	are used for this class. At last, a binary classification was tried, excluding the background completely. For every data type, the training and the validation loss function is shown in fig. \ref{lossall}. 

One expected result would be that the network performs worse on isolated particles since the distinction between background and electromagnetic/hadronic particles is lost. Several events could also fall in both the electromagnetic and the hadronic class, which is more difficult to recognize. The training loss decreases exponentially, which is the expected behaviour. It can also be seen that all analyses have a validation loss that remains constant or even increases. The validation should not worsen as observed as dropout of 0.5 is used during all training time. Increasing dropout had no effect on the training. As the training loss behaves correctly, it can be assumed that the implementation of the network is correct but it seems to be unable to identify physical features which correctly classify the events.

\begin{figure}
\centering
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{trainlossbinary.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{vallossbinary.png}
\end{minipage}
\\
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{trainloss.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{valloss.png}
\end{minipage}
\\\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{trainlossisolated.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{vallossisolated.png}
\end{minipage}
\caption{Training and validation loss for different data sets. At first the binary classification is shown, then the single particles and at last the isolated particles. The correct tendency for the loss function to decrease is seen in every training figure. The validation loss behaves not as it should. It seems to forget what it learned.}
\end{figure}

\begin{figure}
\centering
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{precisionsingle.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{recallsingle.png}
\end{minipage}
\caption{Precision and recall for single particles. The precision is rather high, false positives are therefore seldom. In comparison, recall is low for electrons and hadrons. Many times the network falsely labels an event as not belonging to one of these categories but rather to the background or no class.}
\label{lossall}
\end{figure}
It is interesting that hadronic particles are more easily identified judging by the relatively small loss function. The single particles have the most constant performance on the validation data set but it still seems to increase during training time. The last set in fig. \ref{lossall} is the training with strictly isolated particles. For unknown reasons the background loss function behaves exactly the same as the hadron loss function, during training as well as during validation. 
\subsection{Performance on actual data}
To see how the network performed on actual data after training, two runs with proton-proton collisions at $\sqrt{s}$ = 13 TeV with very low luminosity are evaluated. The low luminosity was useful to ensure that a high number of events contained isolated or single particles. To assess the performance of the network, the ratio of electromagnetic energy deposit contained in the first two sections of every tower to hadronic energy deposit in the following 14 sections is calculated. The energy ratio E$_{\mathrm{em}}$/(E$_{\mathrm{em}}$ + E$_{\mathrm{had}}$)is shown in the histograms in fig. \ref{ratio}, in comparison to actual electromagnetic and hadronic events and their ratio made by Monte Carlo simulations by EPOS. 
\begin{figure}
\centering
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{ratio.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{emhadbinary.png}
\end{minipage}
\\
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{emhadsingle.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=7cm]{emhadisolated.png}
\end{minipage}
\caption{Electromagnetic to hadronic energy in the different categories. The figure on the upper left are simulated events with single electromagnetic and hadronic particles. On the upper right hand side are the ratios based on the prediction trained on binary particles. On the lower left hand side are the predictions based on single particles, on the lower right hand side the predictions based on the isolated particles.}
\label{ratio}
\end{figure}

For electromagnetic events this ratio should be nearly 1, while for hadronic events a peak close to 0 is to be expected. In the simulated events this behaviour is very obvious. There are two peaks in the histogram, one for electromagnetic and one for hadronic events. In the predicted events the tendency cannot be seen. In the real events classified by the network the energy distribution is the same for all predicted categories. As most events do not contain single or isolated particles the energy ratio is centered around 0.5. This is due to several particles per event travelling through CASTOR. Interesting is the varying amount of events predicted as CASTOR by the network trained on single and on isolated particles. As events with isolated particles can also contain several particle tracks at once more events fall into the electromagnetic or hadronic category. For single particles more events are classified as belonging to background since several particle events were excluded as training events for the other two categories.
 
The neural network is unable to correctly identify a high number of events. As in real data single or isolated particles can not be separated, many events contain several particles crossing CASTOR. This is difficult for the network used here to classify correctly. To see if the network is classifying at least some events accurately, events belonging to one class with a probability of at least 80 \% have been picked out. These events are then displayed as two dimensional signal distributions. An electromagnetic and a hadronic event are shown as examples in fig. \ref{electron}. Both have been identified by the neural network trained on single particles, the networks trained on binary and isolated particles identified similar events. The characteristic signature tracks of both particle types are clearly visible. The electromagnetic particle leaves a short track, depositing its energy in the first two sections of one or two towers. A hadronic particle leaves a wider track, decaying into lighter particles, which deposit their energy throughout the detector.
\begin{figure}
\centering
\begin{minipage}{0.45\textwidth}
\includegraphics[width=6cm]{electron.png}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=6cm]{hadron.png}
\end{minipage}
\caption{One electromagnetic and one hadronic event classified by the neural network with a probability higher than 80 \%. On the left the short track of an electron or photon can be seen, depositing nearly all energy in the first two sections. On the right is the wider signature of a hadron.}
\label{electron}
\end{figure}

Thus it seems in principle some events can be correctly identified by the neural network. The performance is not dependent on the data type used for training. Obvious particle tracks which are left by single particles can be recognized by a trained network. Overlapping signals are difficult for the network to discern and classify. In real data isolated or single particles happen seldom. This explains the incorrectly behaving electromagnetic to hadronic ratio. A useful network must therefore be able to handle those.

\subsection{Error analysis}
After several training cycles the loss function of the network still did not converge. Several possible causes for this failure have been mentioned and rectified, such as the definition of background events, very low recall and the network design. But even with only two categories, electron/photon and hadronic events, the loss function continued to show erratic behaviour. The network only performed well on very clear tracks. Events with several particles are not identified correctly. There are many possibilities which caused the poor classification, a few are going to be evaluated here.

The first one is the lack of training time. Neural networks which perform as well or even exceed human performance have an average training time of three weeks. This was not possible during this thesis as a continuous evaluation of the network's performance was needed. 

The second one is the actual distinction between hadronic and electromagnetic events with only the energy deposit as input data. As hadronic events can also cause electromagnetic showers the input signals can seem similar. If several particles cross CASTOR in one event, the overlapping signals can be difficult to distinguish. 

At last using conventional convolutional layers, important physical information gets lost. As the particles always enter the calorimeter from the left side, layers with higher weights and therefore more emphasis on the first sections could perform better than those used here. Convolutional layers share the same weights across the whole input, so no part is highlighted. This is advantageous in classic image recognition, but not for event classification in a calorimeter. Dedicated network layers may be developed to mitigate this and actually profit from it.